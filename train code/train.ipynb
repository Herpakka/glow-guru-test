{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Randon-Myntra-HackerRamp-21/Acne-type/blob/main/Acne_types_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3rYaMmdtA4a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI9IYGN-OdFa",
        "outputId": "505464ff-ac69-4f40-9038-adee6625dbd0"
      },
      "outputs": [],
      "source": [
        "%pip install split-folders\n",
        "\n",
        "import splitfolders\n",
        "splitfolders.ratio('dataset', output=\"output\", seed=1337, ratio=(.8, 0.2)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHcCadECtRj_",
        "outputId": "5f702bbe-884a-4ab4-a6be-ee99bb5ef95a"
      },
      "outputs": [],
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Preprocess data (get all of the pixel values between 0 & 1, also called scaling/normalization)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Setup paths to our data directories\n",
        "train_dir = \"output/train/\"\n",
        "test_dir = \"output/val/\"\n",
        "\n",
        "# Import data from directories and turn it into batches\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    batch_size=16,\n",
        "    target_size=(224, 224),\n",
        "    class_mode=\"categorical\",\n",
        "    seed=42,\n",
        ")\n",
        "valid_data = valid_datagen.flow_from_directory(\n",
        "    directory=test_dir,\n",
        "    batch_size=16,\n",
        "    target_size=(224, 224),\n",
        "    class_mode=\"categorical\",\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCxz3v7qL5jS"
      },
      "outputs": [],
      "source": [
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def create_model(model_url, num_classes=3):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url(str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes(int): Number of output neurons in the output layer, \n",
        "      should be equal to number of target classes, default = 10\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature extractor \n",
        "    layer and Dense output layer with num_classes output neurons.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable = False,   # freeze the already learned patterns\n",
        "                                           name=\"feature_extraction_layer\",\n",
        "                                           input_shape=IMAGE_SHAPE+(3,))  # define the input image shape\n",
        "  # Create our image model\n",
        "  model = tf.keras.Sequential([\n",
        "     feature_extractor_layer,    # use the feature extraction layer as the base\n",
        "     layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")   # create our own output layer\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBN-NM0ZVnto",
        "outputId": "67ee54d9-061b-41a1-97da-e96a238d2310"
      },
      "outputs": [],
      "source": [
        "# Create EfficientNet model\n",
        "efficientnet_model = create_model(efficientnet_url, num_classes=3)\n",
        "# Compile\n",
        "efficientnet_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "# Fit the model\n",
        "efficientnet_history = efficientnet_model.fit(\n",
        "    train_data, epochs=30, validation_data=valid_data\n",
        ")  # name of log files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpEqWYbxxKe_",
        "outputId": "01037065-2c83-4ed9-8775-dd4b8df5cf15"
      },
      "outputs": [],
      "source": [
        "efficientnet_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SAVE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7QBOq_IVuHv",
        "outputId": "2c1d1ed2-e382-48bf-ede4-b8bc3746bf1d"
      },
      "outputs": [],
      "source": [
        "efficientnet_model.save('saved_model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-KhuYYLV4Sp",
        "outputId": "aa8780c7-44a4-43d6-b9c1-c7ae08730ed4"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('saved_model/my_model')\n",
        "\n",
        "# Check its architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7_2a5TOykwG",
        "outputId": "ac94b00c-43bc-403f-f0b7-359ef0e39d82"
      },
      "outputs": [],
      "source": [
        "import pathlib \n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1cMA3nIzn19"
      },
      "outputs": [],
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into (224,224,3).\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255.\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZy9g8mEy2po"
      },
      "outputs": [],
      "source": [
        "# Reconfig pred_and_plot function to work with multi-class images\n",
        "def pred_and_plot(model, filename, class_names=class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction with model\n",
        "  and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Add in logic for multi-class & get pred_class name\n",
        "  if len(pred[0]) > 1:\n",
        "    pred_class = class_names[tf.argmax(pred[0])]\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred[0]))]\n",
        "  \n",
        "  print('Prediction Probabilities : ', pred[0])\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "stHg5GlfzHe0",
        "outputId": "3fc4ede7-b885-491c-e3f2-e98363e9248f"
      },
      "outputs": [],
      "source": [
        "# Make a prediction using model_1\n",
        "pred_and_plot(model=model, filename=\"00022.png\", class_names=class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOLVisa41dPTKjT5Xnuh9vF",
      "include_colab_link": true,
      "mount_file_id": "1af_dZadn25vl523fe9MApRyiPujTqerv",
      "name": "Acne types.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
